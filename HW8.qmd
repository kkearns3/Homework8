---
title: "Homework8"
format: html
toc: TRUE
---

Libraries

```{r}
library(tidyverse)
library(tidymodels)
```

## Reading Data

Read in the data from URL, using a solution from a Stack Overflow post to fix the initial error.

```{r}
bike_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv",
                     locale = locale(encoding="latin1"))

bike_data
```

Rename all columns to make them easier to work with

```{r}
names(bike_data) <- c("date", "rented_bike_count", "hour", "temperature", "humidity",
                      "wind_speed", "visibility", "dew_point", "solar_radiation",
                      "rainfall", "snowfall", "seasons", "holiday", "functioning_day")
```


## Basic EDA

Look at structure, see if there are columns that are an unexpected data type based on the values

- date is char, should be changed to date
- humidity values are stored in a way that makes sense for display (e.g. 37 for 37%), but would need to be divided by 100 if used for computations (unless the computation only involves itself as a variable, e.g. taking the average humidity level)
- seasons, holiday, and functioning_day are character variables that need to be recast as factors
- all other variables are numeric, as expected

```{r}
str(bike_data)
```
Recast date - format appears to be dd/mm/yyyy, due to the presence of strings like "15/03/2018"

```{r}
bike_data <- bike_data |>
  mutate(date = dmy(date))
```

check the min and max dates in each season to see the order the seasons should be in when that column is recast as factor
```{r}
bike_data |>
  group_by(seasons) |>
  summarize(min_date = min(date),
            max_date = max(date)) |>
  arrange(min_date)
```

Convert char columns to factors

```{r}
bike_data <- bike_data |>
  mutate(seasons = factor(seasons,
                          levels = c("Winter", "Spring", "Summer", "Autumn")),
         holiday = as.factor(holiday),
         functioning_day = as.factor(functioning_day))

bike_data
```

Check for missing values 

```{r}
colSums(is.na(bike_data))
```

Basic summaries for numeric columns

```{r}
psych::describe(bike_data)
```

Look at distinct values for the rest of the categorical variables (already did seasons above)

```{r}
bike_data |>
  group_by(holiday) |>
  summarize(count = n())
```

```{r}
bike_data |>
  group_by(functioning_day) |>
  summarize(count = n(),
            total_bikes = sum(rented_bike_count))
```
No bikes can be rented on non-functioning days, so those days should be excluded from the model

## Data rollup

Produce summarized data by:

- grouping by date, seasons, and holiday
- taking the sum of rented_bike_count, rainfall, and snowfall
- taking the mean of temperature, humidity, wind_speed, visibility, dew_point, solar_radiation

```{r}
bike_rollup <- bike_data |>
  filter(functioning_day == "Yes") |>
  group_by(date, seasons, holiday) |>
  summarize(across(c(rented_bike_count, rainfall, snowfall), sum),
            across(c(temperature, humidity, wind_speed, visibility, 
                     dew_point, solar_radiation), mean))

bike_rollup
```

## EDA Part 2

Repeat EDA for the new rollup

### Summary stats

```{r}
psych::describe(bike_rollup)
```

- Noting that the mean for rented_bike_count is now a lot higher, which is expected after removing the non-functioning days, and also after taking the sum for all hours for a specific day and then taking the average of that

```{r}
bike_data |>
  filter(functioning_day == "Yes") |>
  group_by(date) |>
  summarize(daily_bikes = sum(rented_bike_count)) |>
  summarize(mean(daily_bikes))
```

### Plots & Correlation

#### Density plot for daily bikes

```{r}
g <- ggplot(bike_rollup, aes(x = rented_bike_count, fill = seasons))
g + geom_density(alpha = 0.5)
  
```

I expected to see fewer bikes rented per day during the winter, but the density plot shows it's much more of a pronounced difference than I thought. Interesting that it rarely broke 10K bikes in the winter, whereas the that would be an unusually low day for summer and autumn. Also kind of interesting that the summer and spring patterns look almost bimodal, so I will be curious to see if there are correlations among the weather-related variables that may explain that.


#### Correlation

```{r}
bike_rollup |>
  select(where(is.numeric)) |>
  ungroup() |>
  select(-date, -seasons) |>
  cor()
```

Dew point, solar radiation, and temperature all seem to have a relatively strong positive correlation to bikes rented. Dew point is also very strongly correlated to temperature, so it makes sense they would both show high correlation to bikes rented (as opposed to only one of them showing a correlation). Solar radiation is interesting, because it is most highly correlated to rented bike count, and only weakly correlated to temperature, and does not show much of a linear relationship to anything else. It seems a bit odd that solar radiation would be related to the rented bike count, while simultaneously showing very little linear relationship to rainfall and snowfall, considering solar radiation may be impacted significantly by precipitation. 

#### Scatter plots

Running scatter plots on the most highly correlated variables 

```{r}
g <- ggplot(bike_rollup, aes(y = rented_bike_count, x = temperature))

g + geom_point(aes(color = seasons))
```

Kind of cool, can see clear distinctions in the rented counts vs temperature between the different seasons 

```{r}
g <- ggplot(bike_rollup, aes(y = rented_bike_count, 
                             x = solar_radiation, 
                             color = seasons))

g + 
  geom_point() +
  geom_smooth(method = "lm")
```

Definitely can still see the correlation between solar radiation and bike counts, but there's less of a clear pattern to the seasons

```{r}
g <- ggplot(bike_rollup, aes(y = rented_bike_count, x = dew_point, color = seasons))

g + 
  geom_point() + 
  geom_smooth(method = "lm")
```

Looks a lot like the temperature vs rented bikes scatter plot, which kind of makes sense since the dew point is so closely related to the temperature 

## Split the Data

75/25 training to test split

```{r}
# create the split
bike_split <- initial_split(bike_rollup, prop = 0.75, strata = seasons)

# create the training and test data sets
bike_train <- training(bike_split)
bike_test <- testing(bike_split)

```

10-fold CV split

```{r}
# split training set into 10 groups
bike_10_fold <- vfold_cv(bike_train, 10)

```

## Fitting MLR Models

### Data Preprocessing

Create 3 recipes to preprocess the data for use in MLR models

Recipe 1

- define role for date as an ID column so it's not included in the model, but will be retained in the data set
- add new factor that determines whether the day of the week for each date falls on the weekend or during the week
- standardize numeric variables, except for the outcome

```{r}
bike_rec_1 <- recipe(rented_bike_count ~ ., data = bike_train) |>
  update_role(date, new_role = "ID") |>
  step_date(date, features = c("dow")) |>
  step_mutate(part_of_week = factor(if_else(date_dow %in% c("Sat", "Sun"),
                                        "Weekend",
                                        "Weekday"),
                                levels = c("Weekday", "Weekend"))) |>
  step_rm(date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, part_of_week)
  

# view data to make sure it looks okay
bike_rec_1 |>
  prep(training = bike_train) |>
  bake(bike_train)
```

Formula for recipe 1
```{r}
bike_rec_1 |>
  prep(training = bike_train) |>
  formula()
```


Recipe 2

- Same transformations as recipe 1
- Add interactions to the model formula:
    + seasons and holiday
    + seasons and temp
    + temp and rainfall
- On the first pass, I did not have the step_corr in the preprocessing, but the fit_resamples() generated a warning that stated: "prediction from rank-deficient fit; consider predict(., rankdeficient="NA"). There were issues with some computations   A: x1".
    + First, I tried step_zv(), since the tidymodel tutorial had stated that if there are dummy variables with low-frequency values that don't occur in the training data, then it's possible for some of the downstream functions to generate warnings. That didn't work.
    + From other google results, I didn't find much about the exact warning, but there was a really similar one that apparently can happen when there are variables with really high correlation. Dew point and temperature are very highly correlated, so I decided to use step_cor to address this, and it worked.

```{r}
bike_rec_2 <- recipe(rented_bike_count ~ ., data = bike_train) |>
  update_role(date, new_role = "ID") |>
  step_date(date, features = c("dow")) |>
  step_mutate(part_of_week = factor(if_else(date_dow %in% c("Sat", "Sun"),
                                        "Weekend",
                                        "Weekday"),
                                levels = c("Weekday", "Weekend"))) |>
  step_rm(date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, part_of_week) |>
  step_interact(terms = ~ holiday_No.Holiday : starts_with("seasons_") +
                        temperature : starts_with("seasons_") + 
                        temperature : rainfall) |>
  #step_zv(all_predictors()) |>
  step_corr(all_predictors())
  
bike_rec_2 |>
  prep(training = bike_train) |>
  bake(bike_train)
```

Formula for recipe 2
```{r}
bike_rec_2 |>
  prep(training = bike_train) |>
  formula()
```

Recipe 3

- Same transformations and interactions as recipe 2
- Add quadratic terms for the numeric predictors 

Note: On the quadratic step, I initially tried to do `step_poly(all_numeric_predictors())`, but got an error that said "'degree' must be less than number of unique points". A post on Stack Overflow states this is because there must be columns that don't have enough unique values. Since the degree is 2, the variables included in step_poly must have at least 3 unique values. All the dummy variables had only 2 unique values. Moving step_poly before step_interact only produced more errors, so I decided to just list out the original predictor variables.


```{r}

bike_rec_3 <- recipe(rented_bike_count ~ ., data = bike_train) |>
  update_role(date, new_role = "ID") |>
  step_date(date, features = c("dow")) |>
  step_mutate(part_of_week = factor(if_else(date_dow %in% c("Sat", "Sun"),
                                        "Weekend",
                                        "Weekday"),
                                levels = c("Weekday", "Weekend"))) |>
  step_rm(date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, part_of_week) |>
  step_interact(terms = ~ holiday_No.Holiday : starts_with("seasons_") +
                        temperature : starts_with("seasons_") + 
                        temperature : rainfall) |>
  # step_poly(all_numeric_predictors())
  step_poly(rainfall, snowfall, temperature, humidity, wind_speed, visibility,
            dew_point, solar_radiation) |>
  step_corr(all_predictors())
  
bike_rec_3 |>
  prep(training = bike_train) |>
  bake(bike_train)

```

Formula for recipe 3
```{r}
bike_rec_3 |>
  prep(training = bike_train) |>
  formula()
```

### Fit the Models

Using a linear model

```{r}
bike_model <- linear_reg() |>
  set_engine("lm")
```


#### Workflows

Set up workflows to use with 10-fold SV to fit a linear model

Recipe 1

```{r}
bike_wfl_1 <- workflow() |>
  add_recipe(bike_rec_1) |>
  add_model(bike_model)

bike_wfl_1
```


Recipe 2

```{r}
bike_wfl_2 <- workflow() |>
  add_recipe(bike_rec_2) |>
  add_model(bike_model)

bike_wfl_2
```

Recipe 3

```{r}
bike_wfl_3 <- workflow() |>
  add_recipe(bike_rec_3) |>
  add_model(bike_model)

bike_wfl_3
```

#### CV Fit on Model

Have already set up the 10-fold CV split

Model 1

```{r}
bike_CV_fits_1 <- bike_wfl_1 |>
  fit_resamples(bike_10_fold) 

bike_CV_fits_1 |>
  collect_metrics()
```

Model 2

```{r}
bike_CV_fits_2 <- bike_wfl_2 |>
  fit_resamples(bike_10_fold) 

bike_CV_fits_2 |>
  collect_metrics()
```

Model 3

```{r}
bike_CV_fits_3 <- bike_wfl_3 |>
  fit_resamples(bike_10_fold) 

bike_CV_fits_3 |>
  collect_metrics()
```

## Fit on Entire Training Data

I ran the previous code multiple times, and the RMSE for each model was variable. Each of the models had the lowest RMSE at least once, but I feel that the second model seems to come in lowest pretty often, so that's the one I went with.

Fit the best model on the entire training set:

```{r}

bike_wfl_2 |>
  #fit(bike_train) |>
  last_fit(bike_split) |>
  collect_metrics()

```

Fit model on the test data

```{r}
# workflow for 2nd model
#lm_fit <- fit(bike_wfl_2, bike_train)

# prediction for bikes rented on the test set
bike_test_res <- bike_wfl_2 |>
  fit(bike_train) |>
  predict(new_data = bike_test)

bike_test_res
```


Compute RMSE on the test data (confirm model error given above by last_fit)

```{r}
# add in the truth values
bike_test_res <- bike_test_res |>
  bind_cols(bike_test |> ungroup() |> select(rented_bike_count))

# compare to predicted values
bike_test_res |>
  rmse(truth = rented_bike_count, estimate = .pred)
```

## Final Model

Fit on the entire training set, get coefficient table

```{r}
bike_wfl_2 |>
  #last_fit(bike_split) |>
  fit(bike_train) |>
  extract_fit_parsnip() |>
  tidy()

```

Really big coefficients, which might be expected since all numeric predictors were standardized, but the outcome was not. To make sure, I am going to plot the predictions over the original data to make sure it looks okay.

Plot predictions from the test data against the temperature values in that set, since temperature seems to be the most significant predictor

```{r}
# take predictions already made, and combine with temperature values
mlm_points <- bike_test_res[".pred"] |>
  bind_cols(bike_test |> ungroup() |> select(temperature))

# plot original data, with the model line overlay
g <- ggplot(bike_rollup, aes(x = temperature, y = rented_bike_count)) 
g + geom_point(aes(color = seasons)) +
  geom_smooth(data = mlm_points, aes(x = temperature, y = .pred))

```


Hey, it looks pretty good!

